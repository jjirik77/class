<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Tool: AI Tokenization</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@300;400;600;700;800&family=Fira+Code:wght@400;500&display=swap');
        
        :root {
            --primary: #6366f1;
            --primary-light: #818cf8;
            --bg-main: #f8fafc;
        }

        body {
            font-family: 'Plus Jakarta Sans', sans-serif;
            background-color: var(--bg-main);
            color: #1e293b;
            scroll-behavior: smooth;
        }

        .mesh-gradient {
            background-color: #1e293b;
            background-image: 
                radial-gradient(at 0% 0%, hsla(253,16%,7%,1) 0, transparent 50%), 
                radial-gradient(at 50% 0%, hsla(225,39%,30%,1) 0, transparent 50%), 
                radial-gradient(at 100% 0%, hsla(339,49%,30%,1) 0, transparent 50%);
        }

        .glass-card {
            background: rgba(255, 255, 255, 0.8);
            backdrop-filter: blur(12px);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: 0 20px 25px -5px rgb(0 0 0 / 0.05), 0 8px 10px -6px rgb(0 0 0 / 0.05);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }

        /* Interactive Card States */
        .discovery-card {
            cursor: pointer;
            overflow: hidden;
            height: auto;
        }

        .discovery-card .reveal-content {
            max-height: 0;
            opacity: 0;
            transition: all 0.5s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .discovery-card.is-open .reveal-content {
            max-height: 200px;
            opacity: 1;
            margin-top: 1rem;
        }

        .discovery-card .indicator {
            transition: transform 0.3s ease;
        }

        .discovery-card.is-open .indicator {
            transform: rotate(45deg);
        }

        .token-chip {
            display: inline-flex;
            flex-direction: column;
            align-items: center;
            padding: 4px 8px;
            margin: 4px;
            border-radius: 8px;
            font-family: 'Fira Code', monospace;
            font-size: 0.95rem;
            cursor: pointer;
            transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            border: 1px solid rgba(0,0,0,0.05);
        }

        .token-chip:hover {
            transform: scale(1.1);
            z-index: 10;
            box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1);
        }

        .token-id {
            font-size: 0.65rem;
            opacity: 0;
            height: 0;
            transition: all 0.2s;
            font-weight: 700;
        }

        .show-ids .token-id {
            opacity: 0.6;
            height: 12px;
            margin-top: 2px;
        }

        .progress-container {
            background: #e2e8f0;
            height: 10px;
            border-radius: 99px;
            overflow: hidden;
            position: relative;
        }
        .progress-bar {
            height: 100%;
            border-radius: 99px;
            transition: width 1.5s cubic-bezier(0.34, 1.56, 0.64, 1);
        }

        .toggle-switch {
            position: relative;
            display: inline-block;
            width: 44px;
            height: 24px;
        }
        .toggle-switch input { opacity: 0; width: 0; height: 0; }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0; left: 0; right: 0; bottom: 0;
            background-color: #cbd5e1;
            transition: .4s;
            border-radius: 24px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 18px; width: 18px;
            left: 3px; bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider { background-color: var(--primary); }
        input:checked + .slider:before { transform: translateX(20px); }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .animate-entry { animation: fadeIn 0.5s ease-out forwards; }

        .color-0 { background: #dcfce7; color: #166534; border-color: #bbf7d0; }
        .color-1 { background: #dbeafe; color: #1e40af; border-color: #bfdbfe; }
        .color-2 { background: #fef9c3; color: #854d0e; border-color: #fef08a; }
        .color-3 { background: #ffedd5; color: #9a3412; border-color: #fed7aa; }
        .color-4 { background: #fce7f3; color: #9d174d; border-color: #fbcfe8; }
        .color-5 { background: #ede9fe; color: #5b21b6; border-color: #ddd6fe; }
    </style>
</head>
<body>

    <!-- Dynamic Header Section -->
    <header class="mesh-gradient text-white py-20 px-6 relative overflow-hidden">
        <div class="absolute top-0 right-0 w-64 h-64 bg-blue-500 opacity-10 rounded-full blur-3xl -mr-20 -mt-20"></div>
        <div class="absolute bottom-0 left-0 w-96 h-96 bg-indigo-500 opacity-10 rounded-full blur-3xl -ml-40 -mb-40"></div>
        
        <div class="max-w-6xl mx-auto relative z-10 text-center md:text-left">
            <h1 class="text-5xl md:text-7xl font-extrabold mb-6 tracking-tight">
                Decoding <span class="text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-indigo-300">Tokens</span>
            </h1>
            <p class="text-xl md:text-2xl text-indigo-100/80 max-w-3xl leading-relaxed font-light mx-auto md:mx-0">
                Large Language Models don't read words. They process statistical units called tokens. Explore how human language transforms into machine logic.
            </p>
        </div>
    </header>

    <main class="max-w-6xl mx-auto px-6 -mt-12 pb-24 relative z-20">
        
        <!-- Quick Insight Cards (Interactive Discovery) -->
        <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
            <!-- Card 1 -->
            <div onclick="toggleCard(this)" class="discovery-card glass-card p-8 rounded-[2rem] border-b-4 border-blue-500 group">
                <div class="flex justify-between items-start">
                    <div class="w-12 h-12 bg-blue-100 text-blue-600 rounded-2xl flex items-center justify-center mb-6">
                        <i class="fas fa-layer-group text-xl"></i>
                    </div>
                    <i class="fas fa-plus indicator text-slate-300 group-hover:text-blue-500"></i>
                </div>
                <h3 class="text-xl font-bold">What is a Token?</h3>
                <div class="reveal-content">
                    <p class="text-slate-600 text-sm leading-relaxed">
                        A fundamental unit of text used by LLMs to process language. Tokens can be words, parts of words, or characters.
                    </p>
                </div>
                <p class="text-[10px] uppercase tracking-widest font-bold text-slate-400 mt-4 group-[.is-open]:hidden">Click to reveal</p>
            </div>

            <!-- Card 2 -->
            <div onclick="toggleCard(this)" class="discovery-card glass-card p-8 rounded-[2rem] border-b-4 border-indigo-500 group">
                <div class="flex justify-between items-start">
                    <div class="w-12 h-12 bg-indigo-100 text-indigo-600 rounded-2xl flex items-center justify-center mb-6">
                        <i class="fas fa-brain text-xl"></i>
                    </div>
                    <i class="fas fa-plus indicator text-slate-300 group-hover:text-indigo-500"></i>
                </div>
                <h3 class="text-xl font-bold">Building Context</h3>
                <div class="reveal-content">
                    <p class="text-slate-600 text-sm leading-relaxed">
                        Just as pages build a story, tokens build the statistical "understanding" models use to generate responses.
                    </p>
                </div>
                <p class="text-[10px] uppercase tracking-widest font-bold text-slate-400 mt-4 group-[.is-open]:hidden">Click to reveal</p>
            </div>

            <!-- Card 3 -->
            <div onclick="toggleCard(this)" class="discovery-card glass-card p-8 rounded-[2rem] border-b-4 border-emerald-500 group">
                <div class="flex justify-between items-start">
                    <div class="w-12 h-12 bg-emerald-100 text-emerald-600 rounded-2xl flex items-center justify-center mb-6">
                        <i class="fas fa-terminal text-xl"></i>
                    </div>
                    <i class="fas fa-plus indicator text-slate-300 group-hover:text-emerald-500"></i>
                </div>
                <h3 class="text-xl font-bold">Sequence Prediction</h3>
                <div class="reveal-content">
                    <p class="text-slate-600 text-sm leading-relaxed">
                        Models learn relationships between tokens, excelling at predicting the most likely "next token" in any sequence.
                    </p>
                </div>
                <p class="text-[10px] uppercase tracking-widest font-bold text-slate-400 mt-4 group-[.is-open]:hidden">Click to reveal</p>
            </div>
        </div>

        <!-- The Main Interactive Explorer -->
        <section class="glass-card rounded-[2.5rem] overflow-hidden mb-12 shadow-2xl border-indigo-50" id="tool">
            <div class="bg-slate-900 text-white p-8 flex flex-col md:flex-row justify-between items-center gap-6">
                <div>
                    <h2 class="text-2xl font-bold mb-1">Live Tokenization Laboratory</h2>
                    <p class="text-slate-400 text-sm">Visualize exactly how text is fragmented for machine intake.</p>
                </div>
                <div class="flex items-center gap-8">
                    <div class="flex flex-col items-center">
                        <span class="text-[10px] uppercase tracking-widest text-slate-500 mb-1 font-bold">Show IDs</span>
                        <label class="toggle-switch">
                            <input type="checkbox" id="idToggle" onchange="toggleIds()">
                            <span class="slider"></span>
                        </label>
                    </div>
                    <div class="h-12 w-px bg-white/10 hidden md:block"></div>
                    <div class="text-center">
                        <div class="text-[10px] uppercase tracking-widest text-slate-500 mb-1 font-bold">Token Units</div>
                        <div id="tokenCount" class="text-4xl font-black text-indigo-400 font-mono">0</div>
                    </div>
                </div>
            </div>

            <div class="p-8 grid grid-cols-1 lg:grid-cols-2 gap-10">
                <div class="space-y-6">
                    <div class="relative">
                        <label class="text-xs font-bold text-slate-400 uppercase tracking-widest mb-3 block">User Input</label>
                        <textarea id="inputText" class="w-full h-64 p-6 rounded-3xl bg-slate-50 border-2 border-slate-100 focus:border-indigo-400 focus:ring-0 outline-none text-lg transition-all resize-none font-medium placeholder:text-slate-300" placeholder="Type a sentence to see it transform..."></textarea>
                        
                        <div class="absolute bottom-4 right-4 text-[10px] text-slate-400 font-mono">
                            Chars: <span id="charCount">0</span>
                        </div>
                    </div>
                    
                    <div class="flex flex-wrap gap-3">
                        <span class="text-xs text-slate-400 font-bold self-center mr-2">TEMPLATES:</span>
                        <button onclick="setExample('The sun rises in the east.')" class="px-4 py-2 bg-white border border-slate-200 hover:border-indigo-400 rounded-xl text-xs font-bold transition-all hover:shadow-md">The Sun Rises...</button>
                        <button onclick="setExample('unbelievably prehistoric')" class="px-4 py-2 bg-white border border-slate-200 hover:border-indigo-400 rounded-xl text-xs font-bold transition-all hover:shadow-md">Sub-words</button>
                        <button onclick="setExample('3.14159265')" class="px-4 py-2 bg-white border border-slate-200 hover:border-indigo-400 rounded-xl text-xs font-bold transition-all hover:shadow-md">Digits</button>
                    </div>
                </div>

                <div class="flex flex-col h-full">
                    <label class="text-xs font-bold text-slate-400 uppercase tracking-widest mb-3 block">Machine Representation</label>
                    <div id="tokenOutput" class="flex-grow p-8 bg-slate-50/50 rounded-3xl border-2 border-dashed border-slate-200 min-h-[300px] leading-relaxed content-start flex flex-wrap content-start">
                        <div class="w-full flex flex-col items-center justify-center text-slate-300 h-full text-center space-y-4">
                            <i class="fas fa-i-cursor text-4xl opacity-20"></i>
                            <p class="italic text-sm">Begin typing to generate tokens...</p>
                        </div>
                    </div>
                    
                    <div id="insight" class="mt-6 p-6 rounded-2xl bg-indigo-50 border border-indigo-100 text-indigo-900 text-sm hidden animate-entry">
                        <!-- Dynamic insight content -->
                    </div>
                </div>
            </div>
        </section>

        <!-- Theoretical Content Sections -->
        <div class="grid grid-cols-1 lg:grid-cols-5 gap-10">
            
            <div class="lg:col-span-3 space-y-12">
                <!-- Token Limits Visualization -->
                <div class="glass-card p-10 rounded-[3rem]">
                    <div class="flex items-center justify-between mb-8">
                        <h2 class="text-3xl font-extrabold text-slate-900">Token Limits</h2>
                        <i class="fas fa-tachometer-alt text-slate-300 text-2xl"></i>
                    </div>
                    <p class="text-slate-600 mb-10 leading-relaxed">
                        Every model has a "Context Window" — a finite memory capacity. Once you cross this limit, earlier parts of the conversation are permanently lost to ensure performance.
                    </p>
                    
                    <div class="space-y-8">
                        <div>
                            <div class="flex justify-between items-end mb-3">
                                <span class="font-bold text-slate-800">ChatGPT 3.5</span>
                                <span class="text-xs font-black text-slate-400 bg-slate-100 px-2 py-1 rounded">4,096 TOKENS</span>
                            </div>
                            <div class="progress-container"><div class="progress-bar bg-blue-400" style="width: 15%"></div></div>
                        </div>
                        <div>
                            <div class="flex justify-between items-end mb-3">
                                <span class="font-bold text-slate-800">GPT-4 (Standard)</span>
                                <span class="text-xs font-black text-slate-400 bg-slate-100 px-2 py-1 rounded">8,192 TOKENS</span>
                            </div>
                            <div class="progress-container"><div class="progress-bar bg-indigo-500" style="width: 35%"></div></div>
                        </div>
                        <div>
                            <div class="flex justify-between items-end mb-3">
                                <span class="font-bold text-slate-800">Claude 3.5 Sonnet</span>
                                <span class="text-xs font-black text-slate-400 bg-slate-100 px-2 py-1 rounded">200,000 TOKENS</span>
                            </div>
                            <div class="progress-container"><div class="progress-bar bg-emerald-500" style="width: 95%"></div></div>
                        </div>
                    </div>
                </div>

                <!-- Memory & History -->
                <div class="glass-card p-10 rounded-[3rem] bg-indigo-900 text-white relative overflow-hidden group">
                    <div class="absolute -right-10 -bottom-10 w-40 h-40 bg-white/5 rounded-full group-hover:scale-150 transition-transform duration-700"></div>
                    <h3 class="text-2xl font-bold mb-6 flex items-center">
                        <i class="fas fa-brain mr-4 text-indigo-400"></i> Conversation History
                    </h3>
                    <div class="space-y-6 text-indigo-100/80 leading-relaxed">
                        <div class="flex gap-6">
                            <div class="w-1 h-24 bg-indigo-500 rounded-full"></div>
                            <p>
                                Think of it as a <span class="text-white font-bold italic">sliding window</span>. As you add new prompts, the window slides forward. Content at the very beginning eventually falls out of the window and "never happened" as far as the model is concerned.
                            </p>
                        </div>
                        <p class="text-sm border-t border-indigo-800 pt-6">
                            <strong>The Implication:</strong> If your chat becomes too long, you might need to repeat critical instructions or summaries to keep them inside the active context window.
                        </p>
                    </div>
                </div>
            </div>

            <!-- Sidebar Info -->
            <div class="lg:col-span-2 space-y-8">
                <div class="glass-card p-8 rounded-[2.5rem] bg-gradient-to-br from-indigo-500 to-purple-600 text-white shadow-xl">
                    <h3 class="font-black text-xs uppercase tracking-widest mb-6 opacity-70">Case Study</h3>
                    <div class="space-y-6">
                        <div class="bg-white/10 p-4 rounded-2xl">
                            <h4 class="font-bold text-sm mb-2">Example in Practice</h4>
                            <p class="text-xs text-indigo-100 leading-relaxed italic">
                                Input: "The sun rises in the east."<br>
                                Output Tokens: ["The", "sun", "rises", "in", "the", "east", "."]
                            </p>
                        </div>
                        <p class="text-sm leading-relaxed">
                            When generating, the LLM creates tokens sequentially. If asked to complete the sentence, it might generate ["and", "sets", "in", "the", "west", "."].
                        </p>
                    </div>
                </div>

                <div class="glass-card p-10 rounded-[2.5rem] border-2 border-indigo-100">
                    <h3 class="text-xl font-bold mb-6 text-slate-900">Expert Utilization</h3>
                    <ul class="space-y-6">
                        <li class="flex items-start gap-4">
                            <div class="w-8 h-8 rounded-full bg-blue-100 flex items-center justify-center shrink-0">
                                <i class="fas fa-repeat text-[10px] text-blue-600"></i>
                            </div>
                            <div class="text-sm">
                                <span class="font-bold block mb-1">Periodic Summaries</span>
                                <span class="text-slate-500">Every 10-15 messages, ask the AI to summarize the core goals to "reset" the context focus.</span>
                            </div>
                        </li>
                        <li class="flex items-start gap-4">
                            <div class="w-8 h-8 rounded-full bg-emerald-100 flex items-center justify-center shrink-0">
                                <i class="fas fa-check text-[10px] text-emerald-600"></i>
                            </div>
                            <div class="text-sm">
                                <span class="font-bold block mb-1">Efficiency Scaling</span>
                                <span class="text-slate-500">Newer models (GPT-4o) use more efficient tokenizers that can pack more information into a single token unit.</span>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </main>

    <footer class="bg-slate-900 text-slate-500 py-16 px-6 border-t border-slate-800">
        <div class="max-w-6xl mx-auto flex flex-col md:flex-row justify-between items-center gap-8">
            <div class="flex items-center gap-2">
                <div class="w-8 h-8 bg-indigo-500 rounded-lg flex items-center justify-center text-white text-xs font-bold">TX</div>
                <span class="font-bold text-white tracking-tight">TokenExplorer <span class="font-light opacity-50">v2.0</span></span>
            </div>
            <div class="text-sm opacity-50 font-medium">
                
            </div>
        </div>
    </footer>

    <script>
        const input = document.getElementById('inputText');
        const output = document.getElementById('tokenOutput');
        const countDisplay = document.getElementById('tokenCount');
        const charDisplay = document.getElementById('charCount');
        const insight = document.getElementById('insight');
        const idToggle = document.getElementById('idToggle');

        // Toggle card reveal
        function toggleCard(el) {
            el.classList.toggle('is-open');
        }

        function mockTokenize(text) {
            if (!text) return [];
            
            const commonSuffixes = ['ing', 'ed', 'ly', 'tion', 'ness', 'able', 'ment'];
            const commonPrefixes = ['un', 'pre', 're', 'anti', 'dis'];
            
            let chunks = text.split(/(\s+)/);
            let tokens = [];

            chunks.forEach(chunk => {
                if (chunk === '') return;
                
                if (chunk.trim() === '') {
                    tokens.push({ text: chunk, id: 220 }); 
                    return;
                }

                let current = chunk;
                let subTokens = [];

                const punctMatch = current.match(/[.,!?;:]$/);
                let suffixPunct = "";
                if (punctMatch) {
                    suffixPunct = punctMatch[0];
                    current = current.slice(0, -1);
                }

                let processed = false;
                
                for (let pre of commonPrefixes) {
                    if (current.toLowerCase().startsWith(pre) && current.length > pre.length + 2) {
                        subTokens.push(current.substring(0, pre.length));
                        current = current.substring(pre.length);
                        break;
                    }
                }

                for (let suf of commonSuffixes) {
                    if (current.toLowerCase().endsWith(suf) && current.length > suf.length + 2) {
                        subTokens.push(current.substring(0, current.length - suf.length));
                        subTokens.push(current.substring(current.length - suf.length));
                        processed = true;
                        break;
                    }
                }

                if (!processed) {
                    if (current.match(/[0-9]{3,}/)) {
                        subTokens.push(current.substring(0, Math.floor(current.length/2)));
                        subTokens.push(current.substring(Math.floor(current.length/2)));
                    } else {
                        subTokens.push(current);
                    }
                }

                subTokens.forEach(t => {
                    let id = 0;
                    for (let j = 0; j < t.length; j++) id += t.charCodeAt(j);
                    tokens.push({ text: t, id: (id * 43) % 100000 });
                });

                if (suffixPunct) {
                    tokens.push({ text: suffixPunct, id: 13 });
                }
            });

            return tokens;
        }

        function toggleIds() {
            if (idToggle.checked) {
                output.classList.add('show-ids');
            } else {
                output.classList.remove('show-ids');
            }
        }

        function update() {
            const text = input.value;
            const tokens = mockTokenize(text);
            
            if (text.length === 0) {
                output.innerHTML = `
                    <div class="w-full flex flex-col items-center justify-center text-slate-300 h-full text-center space-y-4">
                        <i class="fas fa-i-cursor text-4xl opacity-20"></i>
                        <p class="italic text-sm">Begin typing to generate tokens...</p>
                    </div>`;
                countDisplay.textContent = '0';
                charDisplay.textContent = '0';
                insight.classList.add('hidden');
                return;
            }

            output.innerHTML = '';
            tokens.forEach((t, i) => {
                const span = document.createElement('div');
                span.className = `token-chip color-${i % 6}`;
                
                const textSpan = document.createElement('span');
                textSpan.textContent = t.text.replace(/ /g, '\u00B7');
                
                const idSpan = document.createElement('span');
                idSpan.className = 'token-id';
                idSpan.textContent = t.id;

                span.appendChild(textSpan);
                span.appendChild(idSpan);
                output.appendChild(span);
            });

            countDisplay.textContent = tokens.length;
            charDisplay.textContent = text.length;
            
            showInsight(text, tokens);
        }

        function showInsight(text, tokens) {
            insight.classList.remove('hidden');
            const wordCount = text.trim().split(/\s+/).length;

            if (tokens.length > wordCount * 1.4) {
                insight.innerHTML = `
                    <div class="flex items-center gap-3">
                        <i class="fas fa-microscope text-lg"></i>
                        <div>
                            <strong>Sub-word Split:</strong> You used ${wordCount} words, but the model created ${tokens.length} tokens. 
                            This fragmentation allows the AI to understand rare or complex words by seeing their common root parts.
                        </div>
                    </div>`;
            } else if (text.match(/[0-9]/)) {
                insight.innerHTML = `
                    <div class="flex items-center gap-3">
                        <i class="fas fa-calculator text-lg"></i>
                        <div>
                            <strong>Numerical Logic:</strong> Notice how numbers are often split? 
                            The model doesn't "calculate" digits—it predicts their relationship as text chunks. 
                            This explains why LLMs can sometimes fail at basic arithmetic.
                        </div>
                    </div>`;
            } else {
                insight.innerHTML = `
                    <div class="flex items-center gap-3">
                        <i class="fas fa-lightbulb text-lg"></i>
                        <div>
                            <strong>Efficiency Note:</strong> Common words like "the" or "sun" are single tokens. 
                            The more common a word is in a model's training data, the more likely it is to be a single, efficient token.
                        </div>
                    </div>`;
            }
        }

        function setExample(val) {
            input.value = val;
            update();
            document.getElementById('tool').scrollIntoView({ behavior: 'smooth' });
        }

        input.addEventListener('input', update);
        update();
    </script>
</body>
</html>
